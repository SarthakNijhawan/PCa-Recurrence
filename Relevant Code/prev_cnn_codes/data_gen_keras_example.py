from __future__ import print_function
from numpy.random import seed
seed(1)
from tensorflow import set_random_seed
set_random_seed(1)
from keras.preprocessing.image import ImageDataGenerator
from keras.utils import np_utils
from keras.callbacks import CSVLogger, ModelCheckpoint,ReduceLROnPlateau
import numpy as np
#import resnet
from keras.optimizers import Adam,SGD, RMSprop
import os
import tensorflow as tf
from keras.utils import plot_model
from keras.layers import Conv2D, MaxPooling2D, Flatten
from keras.layers.core import Dropout
from keras.models import Model
from keras.layers import Input, Dense
from keras.utils.np_utils import to_categorical

os.environ["CUDA_VISIBLE_DEVICES"]="0"

#config = tf.ConfigProto()
#config.gpu_options.per_process_gpu_memory_fraction = 0.8
#session = tf.Session(config=config)
# config = tf.ConfigProto()
# config.gpu_options.per_process_gpu_memory_fraction = 0.75
# session = tf.Session(config=config)
#reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.1,
#              patience=2, min_lr=0.0000001)
csv_logger = CSVLogger('spie_NewArch_train_51.csv')

batch_size = 50
nb_classes = 2
nb_epoch = 40
data_augmentation = True

# input image dimensions
img_rows, img_cols = 101,101
# The patch images are RGB.
img_channels = 3

train_data_dir='./train'
val_data_dir='./valid'
train_samples=len(os.listdir(train_data_dir+"/label_0/"))+len(os.listdir(train_data_dir+"/label_1/"))
val_samples=len(os.listdir(val_data_dir+"/label_0/"))+len(os.listdir(val_data_dir+"/label_1/"))

input_img=Input(shape=(img_rows,img_cols,3))
conv1=Conv2D(30, (3, 3),activation='selu')(input_img)
drop1=Dropout(.5)(conv1)
max1=MaxPooling2D((2, 2), strides=(2, 2))(drop1)

conv2=Conv2D(48,(3,3),activation='selu')(max1)
drop2=Dropout(0.5)(conv2)
max2=MaxPooling2D((2,2),strides=(2,2))(drop2)

conv3=Conv2D(70,(3,3),activation='selu')(max2)
drop3=Dropout(0.7)(conv3)
max3=MaxPooling2D((2,2),strides=(2,2))(drop3)

conv4=Conv2D(145,(3,3),activation='selu')(drop3)
drop4=Dropout(0.7)(conv4)
max4=MaxPooling2D((2,2),strides=(2,2))(drop4)

conv5=Conv2D(220,(3,3),activation='selu')(max4)
drop5=Dropout(0.7)(conv5)
max5=MaxPooling2D((2,2),strides=(2,2))(drop5)

# conv6=Conv2D(90,(3,3),activation='relu')(drop5)

# max6=MaxPooling2D((2,2),strides=(2,2))(conv6)
# drop6=Dropout(0.5)(max6)
# conv7=Conv2D(90,(3,3),activation='relu')(drop6)

# max7=MaxPooling2D((2,2),strides=(2,2))(conv7)
# drop7=Dropout(0.5)(max7)

flatten=Flatten()(max5)
dense1=Dense(1024,activation='relu')(flatten)
drop_dense1=Dropout(0.8)(dense1)

dense2=Dense(1024,activation='relu')(drop_dense1)
drop_dense2=Dropout(0.8)(dense2)

prediction=Dense(2,activation='softmax')(drop_dense2)

model=Model(input=[input_img],output=[prediction])
#model.load_weights("./weights/spie_weights_101.h5")

#model = resnet.ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)
checkpointer = ModelCheckpoint(filepath='./weights/spie_weights_101.h5', monitor='val_acc',verbose=1, save_best_only=True)
rmsprop=RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.0)
sgd = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=True)
adam=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)
model.compile(loss='categorical_crossentropy',
              optimizer=sgd,
              metrics=['accuracy'])

# This will do preprocessing and realtime data augmentation:
datagen = ImageDataGenerator(rescale=1.0/255.)
datagen_augmented = ImageDataGenerator(featurewise_center=False,
    samplewise_center=True,
    featurewise_std_normalization=False,
    samplewise_std_normalization=True,
    zca_whitening=False,
    zca_epsilon=1e-6,
    rotation_range=90,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    channel_shift_range=0.2,
    fill_mode='nearest',
    cval=0.,
    horizontal_flip=True,
    vertical_flip=True,
    rescale=1.0/255.,
    preprocessing_function=None)
train_generator_augmented = datagen_augmented.flow_from_directory(
    train_data_dir,
    target_size=(img_cols, img_rows),
    batch_size=batch_size,
    class_mode='categorical')
validation_generator = datagen.flow_from_directory(
    val_data_dir,
    target_size=(img_cols, img_rows),
    batch_size=batch_size,
    class_mode='categorical')
print(model.summary())
# plot_model(model, to_file='spie101.png',show_shapes=True)
plot_model(model, to_file='spie.png',show_shapes=True)
#Fit the model on the batches generated by datagen.flow().
model.fit_generator(
    train_generator_augmented,
    steps_per_epoch=train_samples // batch_size,
    epochs=nb_epoch,
    verbose=1,
    validation_data=validation_generator,
validation_steps=val_samples// batch_size,callbacks=[checkpointer,csv_logger])

# train_x = np.load("train_x_HnE_101.npy")
# train_x = train_x.astype('float32')
# train_x = train_x/255.0
# train_y = np.load("train_y_HnE_101.npy")
# train_y = to_categorical(train_y, num_classes=2)
# print("read train, len",np.count_nonzero(train_y==0),np.count_nonzero(train_y==1))


# val_x = np.load("val_x_HnE_101.npy")
# val_x = val_x.astype('float32')
# val_x = val_x/255.0
# val_y = np.load("val_y_HnE_101.npy")
# val_y = to_categorical(val_y, num_classes=2)
# print("read val, len",np.count_nonzero(val_y==0),np.count_nonzero(val_y==1))

# train_generator_augmented = datagen_augmented.flow(train_x,train_y)
# validation_generator = datagen.flow(val_x,val_y)
# #model.fit(x=train_x, y=train_y, batch_size=30, epochs=50, verbose=1, callbacks=[csv_logger,checkpointer], validation_split=0.0, validation_data=(val_x,val_y), shuffle=True, class_weight=None, sample_weight=None, initial_epoch=1, steps_per_epoch=None, validation_steps=None)
# model.fit_generator(
#     train_generator_augmented,
#     steps_per_epoch=len(train_x)// 32,
#     epochs=nb_epoch,
#     verbose=1,
#     validation_data=validation_generator,
#     validation_steps=len(val_x)// 32,callbacks=[checkpointer,csv_logger])
